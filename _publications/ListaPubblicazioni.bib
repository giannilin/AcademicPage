@article{
 title = {Short-Term Classification Learning Promotes Rapid Global Improvements of Information Processing in Human Brain Functional Connectome},
 type = {article},
 year = {2020},
 identifiers = {[object Object]},
 keywords = {complex network analysis,functional connectivity,functional magnetic resonance imaging,information processing,short-term memory},
 volume = {13},
 websites = {https://www.frontiersin.org/article/10.3389/fnhum.2019.00462/full},
 month = {1},
 day = {14},
 id = {c337f9c8-3a7f-3767-8388-9ce6e53fe95b},
 created = {2020-05-28T14:08:00.955Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:00.955Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {Classification learning is a preeminent human ability within the animal kingdom but the key mechanisms of brain networks regulating learning remain mostly elusive. Recent neuroimaging advancements have depicted human brain as a complex graph machinery where brain regions are nodes and coherent activities among them represent the functional connections. While long-term motor memories have been found to alter functional connectivity in the resting human brain, a graph topological investigation of the short-time effects of learning are still not widely investigated. For instance, classification learning is known to orchestrate rapid modulation of diverse memory systems like short-term and visual working memories but how the brain functional connectome accommodates such modulations is unclear. We used publicly available repositories (openfmri.org) selecting three experiments, two focused on short-term classification learning along two consecutive runs where learning was promoted by trial-by-trial feedback errors, while a further experiment was used as supplementary control. We analyzed the functional connectivity extracted from BOLD fMRI signals, and estimated the graph information processing in the cerebral networks. The information processing capability, characterized by complex network statistics, significantly improved over runs, together with the subject classification accuracy. Instead, null-learning experiments, where feedbacks came with poor consistency, did not provoke any significant change in the functional connectivity over runs. We propose that learning induces fast modifications in the overall brain network dynamics, definitely ameliorating the short-term potential of the brain to process and integrate information, a dynamic consistently orchestrated by modulations of the functional connections among specific brain regions.},
 bibtype = {article},
 author = {Zippo, Antonio G. and Castiglioni, Isabella and Lin, Jianyi and Borsa, Virginia M. and Valente, Maurizio and Biella, Gabriele E. M.},
 journal = {Frontiers in Human Neuroscience}
}

@inBook{
 title = {Analysis of Symbol Statistics in Bicomponent Rational Models},
 type = {inBook},
 year = {2019},
 identifiers = {[object Object]},
 pages = {306-318},
 websites = {http://link.springer.com/10.1007/978-3-030-24886-4_23},
 id = {ae21652d-a593-33cd-a58c-b54eae50538c},
 created = {2020-05-28T14:08:00.526Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:00.526Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {We study the local limit distribution of sequences of random variables representing the number of occurrences of a symbol in words of length n in a regular language, generated at random according to a rational stochastic model. We present an analysis of the main local limits when the finite state automaton defining the stochastic model consists of two primitive components. Our results include an evaluation of the convergence rate, which in the various cases is of an order slightly slower than O(n−1/2).},
 bibtype = {inBook},
 author = {Goldwurm, M. and Lin, J. and Vignati, M.},
 book = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}

@inProceedings{
 title = {Saddle point method in the analysis of pattern statistics for regular languages},
 type = {inProceedings},
 year = {2019},
 identifiers = {[object Object]},
 keywords = {Limit distributions,Local limit laws,Pattern statistics,Rational formal series,Saddle Point Method},
 id = {8c292e00-7b1a-3c88-836e-7d0f2915716a},
 created = {2020-05-28T14:08:00.526Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:00.526Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {In a recent work we have determined the local limit distribution of pattern statistics representing the number of occurrences of a symbol in words of length n in a regular language generated at random according to a suitable stochastic model. Such a model is defined by a finite automaton with weights in ℝ+, consisting of two primitive components, having some transition from the first to the second component. In the present work we extend those results to the case when there is no communication among the components, and hence the associated formal series is the sum of two rational series recognized by finite state automata with primitive transition matrix. We obtain local limit laws of Gaussian type when there is a dominant component or when, in equipotent case, the main terms of mean value and variance are equal. On the contrary, if these terms are not the same then the local limit distribution is a convex combination of Gaussian laws. All convergence rates of our limits are of the order O(n−1/2). This completes the analysis of local limit laws of symbol statistics under a bicomponent stochastic model1.},
 bibtype = {inProceedings},
 author = {Goldwurm, M. and Lin, J. and Vignati, M.},
 booktitle = {CEUR Workshop Proceedings}
}

@article{
 title = {Robust single-sample face recognition by sparsity-driven sub-dictionary learning using deep features},
 type = {article},
 year = {2019},
 identifiers = {[object Object]},
 keywords = {Deep convolutional neural network (DCNN) features,Dictionary learning,Face recognition,Optimal directions (MOD),Single sample per person,Sparse recovery},
 id = {63127058-5233-392c-88f2-6cc3706f8fe6},
 created = {2020-05-28T14:08:00.759Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:00.759Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {Face recognition using a single reference image per subject is challenging, above all when referring to a large gallery of subjects. Furthermore, the problem hardness seriously increases when the images are acquired in unconstrained conditions. In this paper we address the challenging Single Sample Per Person (SSPP) problem considering large datasets of images acquired in the wild, thus possibly featuring illumination, pose, face expression, partial occlusions, and low-resolution hurdles. The proposed technique alternates a sparse dictionary learning technique based on the method of optimal direction and the iterative ℓ 0 -norm minimization algorithm called k-LIMAPS. It works on robust deep-learned features, provided that the image variability is extended by standard augmentation techniques. Experiments show the effectiveness of our method against the hardness introduced above: first, we report extensive experiments on the unconstrained LFW dataset when referring to large galleries up to 1680 subjects; second, we present experiments on very low-resolution test images up to 8 × 8 pixels; third, tests on the AR dataset are analyzed against specific disguises such as partial occlusions, facial expressions, and illumination problems. In all the three scenarios our method outperforms the state-of-the-art approaches adopting similar configurations.},
 bibtype = {article},
 author = {Cuculo, Vittorio and D’amelio, Alessandro and Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi},
 journal = {Sensors (Switzerland)}
}

@inBook{
 title = {A Parallel MCMC Algorithm for the Balanced Graph Coloring Problem},
 type = {inBook},
 year = {2019},
 identifiers = {[object Object]},
 keywords = {Balanced graph coloring,Greedy colorer,Markov Chain Monte Carlo method,Parallel algorithms},
 pages = {161-171},
 websites = {http://link.springer.com/10.1007/978-3-030-20081-7_16},
 id = {21fa0979-f571-3e0f-ba41-50fa8b79b04c},
 created = {2020-05-28T14:08:00.911Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:00.911Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {In parallel computation domain, graph coloring is widely studied in its own and represents a reference problem for scheduling of parallel tasks. Unfortunately, common graph coloring strategies usually focus on minimizing the number of colors without any concern for the sizes of each color class, thus producing highly skewed color class distributions. However, to guarantee efficiency in parallel computations, but also in other application contexts, it is important to keep the color classes highly balanced in their sizes. In this paper we address this challenging issue for large scale graphs, proposing a fast parallel MCMC heuristic for sparse graphs that randomly generates good balanced colorings provided that a sufficient number of colors are made available. We show its effectiveness through some numerical simulations on random graphs.},
 bibtype = {inBook},
 author = {Conte, Donatello and Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi and Petrini, Alessandro},
 book = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}

@article{
 title = {On the complexity of clustering with relaxed size constraints in fixed dimension},
 type = {article},
 year = {2018},
 identifiers = {[object Object]},
 keywords = {Cluster size constraints,Computational complexity,Constrained k-Means,Geometric clustering problems},
 pages = {37-46},
 volume = {717},
 websites = {http://dx.doi.org/10.1016/j.tcs.2017.04.017},
 publisher = {Elsevier B.V.},
 id = {1325fbc2-483b-3c87-8455-c7b13e64db6e},
 created = {2018-04-23T03:55:47.704Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:59:23.328Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {We study the computational complexity of the problem of computing an optimal clustering A1,A2,…,Ak of a set of points assuming that every cluster size |Ai| belongs to a given set M of positive integers. We present a polynomial time algorithm for solving the problem in dimension 1, i.e. when the points are simply rational values, for an arbitrary set M of size constraints, which extends to the ℓ1-norm an analogous procedure known for the Euclidean norm. Moreover, we prove that in dimension 2, assuming Euclidean norm, the problem is (strongly) NP-hard with size constraints M=2,4. This result is extended also to the size constraints M=2,3 both in the case of Euclidean and ℓ1-norm.},
 bibtype = {article},
 author = {Goldwurm, Massimiliano and Lin, Jianyi and Saccà, Francesco},
 journal = {Theoretical Computer Science}
}

@inProceedings{
 title = {A local limit property for pattern statistics in bicomponent stochastic models},
 type = {inProceedings},
 year = {2018},
 identifiers = {[object Object]},
 id = {da097c32-649c-3ec9-819f-cd59e0e5217a},
 created = {2020-05-28T14:08:00.525Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:00.525Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {We present a non-Gaussian local limit theorem for the number of occurrences of a given symbol in a word of length n generated at random. The stochastic model for the random generation is defined by a rational formal series with non-negative real coefficients. The result yields a local limit towards a uniform density function and holds under the assumption that the formal series defining the model is recognized by a weighted finite state automaton with two primitive components having equal dominant eigenvalue.},
 bibtype = {inProceedings},
 author = {Goldwurm, Massimiliano and Lin, Jianyi and Vignati, Marco},
 booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}

@inProceedings{
 title = {Single Sample Face Recognition by Sparse Recovery of Deep-Learned LDA Features},
 type = {inProceedings},
 year = {2018},
 identifiers = {[object Object]},
 id = {fe9170d9-0dc3-3a47-8c52-c7d4e66d1c58},
 created = {2020-05-28T14:08:00.726Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:00.726Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {Single Sample Per Person (SSPP) Face Recognition is receiving a significant attention due to the challenges it opens especially when conceived for real applications under unconstrained environments. In this paper we propose a solution combining the effectiveness of deep convolutional neural networks (DCNN) feature characterization, the discriminative capability of linear discriminant analysis (LDA), and the efficacy of a sparsity based classifier built on the k -LiMapS&nbsp;algorithm. Experiments on the public LFW dataset prove the method robustness to solve the SSPP problem, outperforming several state-of-the-art methods.},
 bibtype = {inProceedings},
 author = {Bodini, Matteo and D’Amelio, Alessandro and Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi},
 booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}

@book{
 title = {Within network learning on big graphs using secondary memory-based random walk kernels},
 type = {book},
 year = {2017},
 source = {Studies in Computational Intelligence},
 identifiers = {[object Object]},
 volume = {693},
 id = {a7534d22-9dd5-33f5-b840-0dc9fa848151},
 created = {2018-04-23T03:55:47.429Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:59:26.492Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {© Springer International Publishing AG 2017. Significant advances in high-throughput sequencing technologies raised exponentially the rate of acquisition of novel biological knowledge in the last decade, thus resulting in consistent difficulties in the analysis of vast amount of biological data. This adverse scenario is exacerbated by serious scalability limitations affecting state-of-the art within-network learning methods and by the limited availability of primary memory in off-the-shelf desktop computers. In this contribution we present the application of a novel graph kernel, transductive and secondary memory-based network learning algorithm able to effectively tackle the aforementioned limitations. The proposed algorithm is then evaluated on a large (more than 200,000 vertices) biological network using ordinary off-the-shelf computers. To our knowledge this is the first time a graph kernel learning method is applied to a so large biological network.},
 bibtype = {book},
 author = {Lin, J. and Mesiti, M. and Re, M. and Valentini, G.}
}

@article{
 title = {Sparse decomposition by iterating Lipschitzian-type mappings},
 type = {article},
 year = {2017},
 identifiers = {[object Object]},
 keywords = {Fixed-point iteration scheme,Lipschitzian mappings,Smooth ℓ0-norm,Smooth ℓ1-norm,Sparse recovery,Underdetermined linear systems},
 pages = {12-28},
 volume = {664},
 websites = {http://dx.doi.org/10.1016/j.tcs.2016.04.025},
 publisher = {Elsevier B.V.},
 id = {531be054-d856-3d55-8a46-6df17b36f92a},
 created = {2018-04-23T03:55:47.653Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2019-07-29T14:42:48.110Z},
 read = {true},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {This paper provides the analysis of a fast iterative method for finding sparse solutions to underdetermined linear systems. It is based on a fixed-point iteration scheme which combines nonconvex Lipschitzian-type mappings with canonical orthogonal projectors. The former are aimed at uniformly enhancing the sparsity level by shrinkage effects, the latter are used to project back onto the space of feasible solutions. The iterative process is driven by an increasing sequence of a scalar parameter that mainly contributes to approach the sparsest solutions. It is shown that the minima are locally asymptotically stable for a specific smooth ℓ0-norm. Furthermore, it is shown that the points yielded by this iterative strategy are related to the optimal solutions measured in terms of a suitable smooth ℓ1-norm. Numerical simulations on phase transition show that the performances of the proposed technique overcome those yielded by well known methods for sparse recovery.},
 bibtype = {article},
 author = {Adamo, Alessandro and Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi},
 journal = {Theoretical Computer Science}
}

@article{
 title = {Orthogonal procrustes analysis for dictionary learning in sparse linear representation},
 type = {article},
 year = {2017},
 identifiers = {[object Object]},
 pages = {1-16},
 volume = {12},
 id = {02133019-a277-387a-8515-f11810a03922},
 created = {2018-04-23T03:55:47.677Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:59:05.466Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {In the sparse representation model, the design of overcomplete dictionaries plays a key role for the effectiveness and applicability in different domains. Recent research has produced several dictionary learning approaches, being proven that dictionaries learnt by data examples significantly outperform structured ones, e.g. wavelet transforms. In this context, learning consists in adapting the dictionary atoms to a set of training signals in order to promote a sparse representation that minimizes the reconstruction error. Finding the best fitting dictionary remains a very difficult task, leaving the question still open. A well-established heuristic method for tackling this problem is an iterative alternating scheme, adopted for instance in the well-known K-SVD algorithm. Essentially, it consists in repeating two stages; the former promotes sparse coding of the training set and the latter adapts the dictionary to reduce the error. In this paper we present R-SVD, a new method that, while maintaining the alternating scheme, adopts the Orthogonal Procrustes analysis to update the dictionary atoms suitably arranged into groups. Comparative experiments on synthetic data prove the effectiveness of R-SVD with respect to well known dictionary learning algorithms such as K-SVD, ILS-DLA and the online method OSDL. Moreover, experiments on natural data such as ECG compression, EEG sparse representation, and image modeling confirm R-SVD's robustness and wide applicability.;},
 bibtype = {article},
 author = {Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi},
 journal = {PLoS ONE},
 number = {1}
}

@inProceedings{
 title = {IFSM fractal image compression with entropy and sparsity constraints: A sequential quadratic programming approach},
 type = {inProceedings},
 year = {2017},
 identifiers = {[object Object]},
 volume = {1798},
 id = {02bfa595-7ce0-30aa-9f85-0cb856aa4fa2},
 created = {2018-08-01T13:07:25.322Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-08-01T13:07:25.322Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {false},
 hidden = {false},
 private_publication = {true},
 abstract = {© 2017 Author(s). We consider the inverse problem associated with IFSM: Given a target function f, find an IFSM, such that its fixed point f is sufficiently close to f in the Lpdistance. Forte and Vrscay [1] showed how to reduce this problem to a quadratic optimization model. In this paper, we extend the collage-based method developed by Kunze, La Torre and Vrscay ([2][3][4]), by proposing the minimization of the 1-norm instead of the 0-norm. In fact, optimization problems involving the 0-norm are combinatorial in nature, and hence in general NP-hard. To overcome these difficulties, we introduce the 1-norm and propose a Sequential Quadratic Programming algorithm to solve the corresponding inverse problem. As in Kunze, La Torre and Vrscay [3] in our formulation, the minimization of collage error is treated as a multi-criteria problem that includes three different and conflicting criteria i.e., collage error, entropy and sparsity. This multi-criteria program is solved by means of a scalarization technique which reduces the model to a single-criterion program by combining all objective functions with different trade-off weights. The results of some numerical computations are presented.},
 bibtype = {inProceedings},
 author = {Kunze, H. and La Torre, D. and Lin, J.},
 booktitle = {AIP Conference Proceedings}
}

@book{
 title = {A Note on Modelling a Somatic Motor Space for Affective Facial Expressions},
 type = {book},
 year = {2017},
 source = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
 identifiers = {[object Object]},
 keywords = {Emotion,Human-agent interaction,Kalman filter,Probabilistic generative models,Simulation},
 volume = {10590 LNCS},
 id = {062fbd53-47d2-3727-9284-92e393b56615},
 created = {2018-08-01T13:07:25.472Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-08-01T13:07:25.472Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {false},
 hidden = {false},
 private_publication = {true},
 abstract = {© 2017, Springer International Publishing AG. We discuss modelling issues related to the design of a somatic facial motor space. The variants proposed are conceived to be part of a larger system for dealing with simulation-based face emotion analysis along dual interactions.},
 bibtype = {book},
 author = {D’Amelio, A. and Cuculo, V. and Grossi, G. and Lanzarotti, R. and Lin, J.}
}

@article{
 title = {Exact algorithms for size constrained 2-clustering in the plane},
 type = {article},
 year = {2016},
 identifiers = {[object Object]},
 keywords = {Algorithms for clustering,Cluster size constraints,Convex hull,Euclidean norm,K-Set,Manhattan norm},
 pages = {80-95},
 volume = {629},
 websites = {http://dx.doi.org/10.1016/j.tcs.2015.10.005},
 publisher = {Elsevier B.V.},
 id = {b296b30e-6aab-3335-99f7-4d4e6ad1d0e3},
 created = {2018-04-23T03:55:47.418Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:57:08.891Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {We study the problem of determining an optimal bipartition A, B of a set X of n points in R2, under the size constraints |A|=k and |B|=n-k, that minimizes the dispersion of points around their centroid in A and B, both in the cases of Euclidean and Manhattan norms. Under the Euclidean norm, we show that the problem can be solved in O(nk3log2 n) time by using known properties on k-sets and convex hulls; moreover, the solutions for all k=1, 2,..., n/2 can be computed in O(n2log n) time. In the case of Manhattan norm, we present an algorithm working in O(n2log n) time, which uses an extended version of red-black trees to maintain a bipartition of a planar point set. Also in this case we provide a full version of the algorithm yielding the solutions for all size constraints k. All these procedures work in O(n) space and rely on separation results of the clusters of optimal solutions.},
 bibtype = {article},
 author = {Lin, Jianyi and Bertoni, Alberto and Goldwurm, Massimiliano},
 journal = {Theoretical Computer Science}
}

@article{
 title = {Robust Face Recognition Providing the Identity and Its Reliability Degree Combining Sparse Representation and Multiple Features},
 type = {article},
 year = {2016},
 identifiers = {[object Object]},
 keywords = {Face recognition,multi-features,reliability degree,sparse representation},
 volume = {30},
 id = {28925131-830c-38b3-820e-cbf027991b1e},
 created = {2018-04-23T03:55:47.630Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:56:56.043Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {© 2016 World Scientific Publishing Company. For decades, face recognition (FR) has attracted a lot of attention, and several systems have been successfully developed to solve this problem. However, the issue deserves further research effort so as to reduce the still existing gap between the computer and human ability in solving it. Among the others, one of the human skills concerns his ability in naturally conferring a "degree of reliability" to the face identification he carried out. We believe that providing a FR system with this feature would be of great help in real application contexts, making more flexible and treatable the identification process. In this spirit, we propose a completely automatic FR system robust to possible adverse illuminations and facial expression variations that provides together with the identity the corresponding degree of reliability. The method promotes sparse coding of multi-feature representations with LDA projections for dimensionality reduction, and uses a multistage classifier. The method has been evaluated in the challenging condition of having few (3-5) images per subject in the gallery. Extended experiments on several challenging databases (frontal faces of Extended YaleB, BANCA, FRGC v2.0, and frontal faces of Multi-PIE) show that our method outperforms several state-of-The-Art sparse coding FR systems, thus demonstrating its effectiveness and generalizability.},
 bibtype = {article},
 author = {Grossi, G. and Lanzarotti, R. and Lin, J.},
 journal = {International Journal of Pattern Recognition and Artificial Intelligence},
 number = {10}
}

@article{
 title = {RANKS: A flexible tool for node label ranking and classification in biological networks},
 type = {article},
 year = {2016},
 identifiers = {[object Object]},
 pages = {2872-2874},
 volume = {32},
 id = {48e9c692-4eeb-3e78-a26f-3614093571ae},
 created = {2018-04-23T03:55:47.927Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:56:42.648Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {RANKS is a flexible software package that can be easily applied to any bioinformatics task formalisable as ranking of nodes with respect to a property given as a label, such as automated protein function prediction, gene disease prioritization and drug repositioning. To this end RANKS provides an efficient and easy-to-use implementation of kernelized score functions, a semi-supervised algorithmic scheme embedding both local and global learning strategies for the analysis of biomolecular networks. To facilitate comparative assessment, baseline network-based methods, e.g. label propagation and random walk algorithms, have also been implementedAvailability and implementation: The package is available from CRAN: https://cran.r-project.org/ The package is written in R, except for the most computationally intensive functionalities which are implemented in C. CONTACT valentini@di.unimi.it SUPPLEMENTARY INFORMATION: Supplementary Information are available at Bioinformatics online.},
 bibtype = {article},
 author = {Valentini, Giorgio and Armano, Giuliano and Frasca, Marco and Lin, Jianyi and Mesiti, Marco and Re, Matteo},
 journal = {Bioinformatics},
 number = {18}
}

@article{
 title = {SVD-phy: improved prediction of protein functional associations through singular value decomposition of phylogenetic profiles},
 type = {article},
 year = {2016},
 identifiers = {[object Object]},
 pages = {1085-1087},
 volume = {32},
 websites = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btv696},
 month = {4},
 day = {1},
 id = {c7d9359a-b037-387a-a4e8-be18b7708102},
 created = {2018-05-25T07:40:12.291Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-05-25T07:40:16.400Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {A successful approach for predicting functional associations between non-homologous genes is to compare their phylogenetic distributions. We have devised a phylogenetic profiling algorithm, SVD-Phy, which uses truncated singular value decomposition to address the problem of uninformative profiles giving rise to false positive predictions. Benchmarking the algorithm against the KEGG pathway database, we found that it has substantially improved performance over existing phylogenetic profiling methods.\n\nAVAILABILITY AND IMPLEMENTATION: The software is available under the open-source BSD license at https://bitbucket.org/andrea/svd-phy CONTACT: lars.juhl.jensen@cpr.ku.dk.},
 bibtype = {article},
 author = {Franceschini, Andrea and Lin, Jianyi and von Mering, Christian and Jensen, Lars Juhl},
 journal = {Bioinformatics},
 number = {7}
}

@inProceedings{
 title = {On the complexity of clustering with relaxed size constraints},
 type = {inProceedings},
 year = {2016},
 identifiers = {[object Object]},
 keywords = {Cluster size constraints,Computational complexity,Constrained k-means,Geometric clustering problems},
 pages = {26-38},
 volume = {9778},
 id = {57ba69dd-92a7-36f9-ac4e-5465322fc0ea},
 created = {2020-05-28T13:59:34.340Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2020-05-28T14:08:01.198Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {We study the computational complexity of the problem of computing an optimal clustering A1, A2, …,Ak of a set of points assuming that every cluster size |Ai| belongs to a given set M of positive integers. We present a polynomial time algorithm for solving the problem in dimension 1, i.e. when the points are simply rational values, for an arbitrary set M of size constraints, which extends to the ℓ1-norm an analogous procedure known for the ℓ2-norm. Moreover, we prove that in the Euclidean plane, i.e. assuming dimension 2 and ℓ2-norm, the problem is NP-hard even with size constraints set reduced to M = 2, 3.},
 bibtype = {inProceedings},
 author = {Goldwurm, Massimiliano and Lin, Jianyi and Saccà, Francesco},
 booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}

@article{
 title = {Robust face recognition using sparse representation in LDA space},
 type = {article},
 year = {2015},
 identifiers = {[object Object]},
 keywords = {Face recognition,Fixed-point iteration schema,Nonlinear nonconvex mappings,SRC, CRC, LASSO, WSRC algorithms,Sparsity recovery},
 pages = {837-847},
 volume = {26},
 publisher = {Springer Berlin Heidelberg},
 id = {d65b5596-da26-3563-94cd-fdfd49e975b3},
 created = {2018-04-23T03:55:47.758Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:57:16.199Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 bibtype = {article},
 author = {Adamo, Alessandro and Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi},
 journal = {Machine Vision and Applications},
 number = {6}
}

@article{
 title = {High-rate compression of ECG signals by an accuracy-driven sparsity model relying on natural basis},
 type = {article},
 year = {2015},
 identifiers = {[object Object]},
 keywords = {Cardiac arrhythmia,ECG compression,High compression ratio,PRDN guaranteed,Sparse representation},
 pages = {96-106},
 volume = {45},
 websites = {http://dx.doi.org/10.1016/j.dsp.2015.06.006},
 publisher = {Elsevier Inc.},
 id = {de330a95-226a-3402-862e-5bd92bd2f113},
 created = {2018-04-23T03:55:47.841Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2019-05-09T22:09:02.318Z},
 read = {true},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {Abstract Long duration recordings of ECG signals require high compression ratios, in particular when storing on portable devices. Most of the ECG compression methods in literature are based on wavelet transform while only few of them rely on sparsity promotion models. In this paper we propose a novel ECG signal compression framework based on sparse representation using a set of ECG segments as natural basis. This approach exploits the signal regularity, i.e. the repetition of common patterns, in order to achieve high compression ratio (CR). We apply k-LiMapS as fine-tuned sparsity solver algorithm guaranteeing the required signal reconstruction quality PRDN (Normalized Percentage Root-mean-square Difference). Extensive experiments have been conducted on all the 48 records of MIT-BIH Arrhythmia Database and on some 24 hour records from the Long-Term ST Database. Direct comparisons of our method with several state-of-the-art ECG compression methods (namely ARLE, Rajoub's, SPIHT, TRE) prove its effectiveness. Our method achieves average performances that are two-three times higher than those obtained by the other assessed methods. In particular the compression ratio gap between our method and the others increases with growing PRDN.},
 bibtype = {article},
 author = {Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi},
 journal = {Digital Signal Processing: A Review Journal}
}

@article{
 title = {ECG compression retaining the best natural basis k-coefficients via sparse decomposition},
 type = {article},
 year = {2015},
 identifiers = {[object Object]},
 keywords = {ECG compression,Fixed-point iteration scheme,Orthogonal projections,Sparsity recovery},
 pages = {11-17},
 volume = {15},
 websites = {http://dx.doi.org/10.1016/j.bspc.2014.09.002},
 publisher = {Elsevier Ltd},
 id = {ed29557c-cc40-32df-989f-5d53f5d16dcd},
 created = {2018-04-23T03:55:47.914Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:56:29.709Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {A novel and efficient signal compression algorithm aimed at finding the sparsest representation of electro-cardiogram (ECG) signals is presented and analyzed. The idea behind the method relies on basis elementsdrawn from the initial transitory of a signal itself, and the sparsity promotion process applied to its sub-sequent blocks grabbed by a sliding window. The saved coefficients rescaled in a convenient range, quantized and compressed by a lossless entropy-based algorithm. Experiments on signals extracted from the MIT-BIH Arrhythmia database show that the methodachieves in most of the cases very high performance.},
 bibtype = {article},
 author = {Adamo, Alessandro and Grossi, Giuliano and Lanzarotti, Raffaella and Lin, Jianyi},
 journal = {Biomedical Signal Processing and Control}
}

@book{
 title = {A selection module for large-scale face recognition systems},
 type = {book},
 year = {2015},
 source = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
 identifiers = {[object Object]},
 volume = {9280},
 id = {c8c4e6e9-dade-36f0-9b7d-8f7cdd4f8731},
 created = {2018-08-01T13:07:25.233Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-08-01T13:07:25.233Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {false},
 hidden = {false},
 private_publication = {true},
 abstract = {© Springer International Publishing Switzerland 2015. Face recognition systems aimed at working on large scale datasets are required to solve specific hurdles. In particular, due to the huge amount of data, it becomes mandatory to furnish a very fast and effective approach. Moreover the solution should be scalable, that is it should deal efficiently the growing of the gallery with new subjects. In literature, most of the works tackling this problem are composed of two stages, namely the selection and the classification. The former is aimed at significantly pruning the face image gallery, while the latter, often expensive but precise, determines the probe identity on this reduced domain. In this article a new selection method is presented, combining a multi-feature representation and the least squares method. Data are split into sub-galleries so as to make the system more efficient and scalable. Experiments on the union of four challenging datasets and comparisons with the state-of-the-art prove the effectiveness of our method.},
 bibtype = {book},
 author = {Grossi, G. and Lanzarotti, R. and Lin, J.}
}

@book{
 title = {Exact algorithms for 2-clustering with size constraints in the Euclidean plane},
 type = {book},
 year = {2015},
 source = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
 identifiers = {[object Object]},
 keywords = {Algorithms for clustering,Cluster size constraints,Data analysis,Euclidean distance,Machine learning},
 volume = {8939},
 id = {1a48dce1-79fd-36ea-99f2-cf33160c289a},
 created = {2018-08-01T13:07:25.316Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-08-01T13:07:25.316Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {false},
 hidden = {false},
 private_publication = {true},
 abstract = {© Springer-Verlag Berlin Heidelberg 2015. We study the problem of determining an optimal bipartition A,B of a set X of n points in R&lt;sup&gt;2&lt;/sup&gt; that minimizes the sum of the sample variances of A and B, under the size constraints |A| = k and |B| = n–k. We present two algorithms for such a problem. The first one computes the solution in O(n&lt;sup&gt;3&lt;/sup&gt;√k log&lt;sup&gt;2&lt;/sup&gt; n) time by using known results on convexhulls and k-sets. The second algorithm, for an input X ⊂ R&lt;sup&gt;2&lt;/sup&gt; of size n, solves the problem for all k = 1, 2,..., ⌊n/2⌋ and works in O(n&lt;sup&gt;2&lt;/sup&gt; log n) time.},
 bibtype = {book},
 author = {Bertoni, A. and Goldwurm, M. and Lin, J.}
}

@inProceedings{
 title = {STRING 9 . 1 — a resource for protein interaction networks},
 type = {inProceedings},
 year = {2014},
 pages = {9},
 id = {f595c6de-64f8-3aba-8653-ee9f73e0f2f0},
 created = {2014-03-25T22:27:13.000Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2017-03-17T12:10:13.705Z},
 read = {true},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 bibtype = {inProceedings},
 author = {Franceschini, Andrea and Roth, Alexander and Szklarczyk, Damian and Simonovic, Milan and Kuhn, Michael and Minguez, Pablo and Lin, Jianyi and Bork, Peer and Jensen, Lars J and Mering, Christian Von},
 booktitle = {SIB Days}
}

@inProceedings{
 title = {Size-constrained 2-clustering in the plane with Manhattan distance},
 type = {inProceedings},
 year = {2014},
 identifiers = {[object Object]},
 keywords = {Algorithms and data structures,Cluster size constraints,Clustering,Manhattan distance},
 volume = {1231},
 id = {9d7320a4-4c87-3837-ad1d-127cf77e1fde},
 created = {2018-08-01T13:07:25.233Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-08-01T13:07:25.233Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {false},
 hidden = {false},
 private_publication = {true},
 abstract = {We present an algorithm for the 2-clustering problem with cluster size constraints in the plane assuming l1-norm, that works in O(n3logn) time and O(n) space. Such a procedure also solves a full version of the problem, computing the optimal solutions for all possible constraints on cluster sizes. The algorithm is based on a separation result concerning the clusters of any optimal solution of the problem and on an extended version of red-black trees to maintain a bipartition of a set of points in the plane.},
 bibtype = {inProceedings},
 author = {Bertoni, A. and Goldwurm, M. and Lin, J. and Pini, L.},
 booktitle = {CEUR Workshop Proceedings}
}

@article{
 title = {STRING v9.1: protein-protein interaction networks, with increased coverage and integration.},
 type = {article},
 year = {2013},
 identifiers = {[object Object]},
 keywords = {Algorithms,Data Interpretation,Data Mining,Databases,Internet,Protein,Protein Interaction Mapping,Statistical,Systems Integration,User-Computer Interface},
 pages = {D808-15},
 volume = {41},
 websites = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3531103&amp;tool=pmcentrez&amp;rendertype=abstract},
 id = {7a483863-689e-3c58-b422-ad65831c1c00},
 created = {2018-04-23T03:55:47.833Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:58:41.494Z},
 read = {true},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 abstract = {Complete knowledge of all direct and indirect interactions between proteins in a given cell would represent an important milestone towards a comprehensive description of cellular mechanisms and functions. Although this goal is still elusive, considerable progress has been made-particularly for certain model organisms and functional systems. Currently, protein interactions and associations are annotated at various levels of detail in online resources, ranging from raw data repositories to highly formalized pathway databases. For many applications, a global view of all the available interaction data is desirable, including lower-quality data and/or computational predictions. The STRING database (http://string-db.org/) aims to provide such a global perspective for as many organisms as feasible. Known and predicted associations are scored and integrated, resulting in comprehensive protein networks covering &gt;1100 organisms. Here, we describe the update to version 9.1 of STRING, introducing several improvements: (i) we extend the automated mining of scientific texts for interaction information, to now also include full-text articles; (ii) we entirely re-designed the algorithm for transferring interactions from one model organism to the other; and (iii) we provide users with statistical information on any functional enrichment observed in their networks.},
 bibtype = {article},
 author = {Franceschini, Andrea and Szklarczyk, Damian and Frankild, Sune and Kuhn, Michael and Simonovic, Milan and Roth, Alexander and Lin, Jianyi and Minguez, Pablo and Bork, Peer and Von Mering, Christian and Jensen, Lars J.},
 journal = {Nucleic acids research},
 number = {D1}
}

@inProceedings{
 title = {Size constrained clustering problems in fixed dimension},
 type = {inProceedings},
 year = {2012},
 websites = {http://ictcs.di.unimi.it/slides/Lin.pdf},
 id = {45378a44-5f72-3e4e-942c-9e94f821b027},
 created = {2014-03-25T10:05:34.000Z},
 accessed = {2014-03-25},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:55:50.263Z},
 read = {true},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 bibtype = {inProceedings},
 author = {Jianyi, LIN},
 booktitle = {Ictcs.Di.Unimi.It}
}

@article{
 title = {Size constrained distance clustering: Separation properties and some complexity results},
 type = {article},
 year = {2012},
 identifiers = {[object Object]},
 keywords = {NP-hardness,clustering,size constraints},
 volume = {115},
 id = {6423ed31-ea76-36b7-a5a8-58385ac12480},
 created = {2018-08-01T13:07:25.448Z},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-08-01T13:07:25.448Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {false},
 hidden = {false},
 private_publication = {true},
 abstract = {In this paper we study the complexity of some size constrained clustering problems with norm Lp. We obtain the following results: (i) A separation property for the constrained 2-clustering problem. This implies that the optimal solutions in the 1-dimensional case verify the so-called "String Property"; (ii) The NP-hardness of the constrained 2-clustering problem for every norm Lp(p &gt; 1); (iii) A polynomial time algorithm for the constrained 2-clustering problem in dimension 1 for every norm Lpwith integer p. We also give evidence that this result cannot be extended to norm Lpwith rational non-integer p; (iv) The NP-hardness of the constrained clustering problem in dimension 1 for every norm Lp(p ≥ 1).},
 bibtype = {article},
 author = {Bertoni, A. and Goldwurm, M. and Lin, J. and Saccà, F.},
 journal = {Fundamenta Informaticae},
 number = {1}
}

@inProceedings{
 title = {Modeling neuronal ensemble firing activity through intermittent Chaos},
 type = {inProceedings},
 year = {2010},
 identifiers = {[object Object]},
 pages = {1593-1598},
 websites = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5645262},
 month = {9},
 publisher = {IEEE},
 id = {8092fbf7-d689-3c16-b627-888aae5009ea},
 created = {2014-03-25T15:27:36.000Z},
 accessed = {2014-03-25},
 file_attached = {false},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2017-03-17T12:10:13.705Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 language = {English},
 private_publication = {false},
 bibtype = {inProceedings},
 author = {Storchi, Riccardo and Zippo, Antonio G. and Caramenti, Giancarlo and Valente, Maurizio and Lin, Jianyi and Biella, Gabriele E.M.},
 booktitle = {2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA)}
}

@article{
 title = {A derivation of the statistical characteristics of forest fires},
 type = {article},
 year = {2009},
 keywords = {Forest fires,Model,Power law,Scaling law,Vegetational growth,Wildfire statistics},
 pages = {898-903},
 volume = {220},
 id = {526d83d1-b3a0-3665-807a-d9478676f434},
 created = {2014-03-25T09:53:03.000Z},
 file_attached = {true},
 profile_id = {6bce6ab9-03b5-36ad-a474-26e482dc52c3},
 last_modified = {2018-04-23T03:56:19.105Z},
 read = {false},
 starred = {false},
 authored = {true},
 confirmed = {true},
 hidden = {false},
 private_publication = {false},
 bibtype = {article},
 author = {Lin, Jianyi and Rinaldi, Sergio},
 journal = {Ecological Modelling},
 number = {7}
}

